Column generation:
       suppose we get a fathomed tour on a sparse edge set. This means we have
       optimal primal/dual solutions and reduced costs. This could just mean
       we need to price/add more edges, but for the existing edges, we could
       use optimality to prune by reduced cost before scanning the edge set. 

Add a 'picky' switch to the Gomory cuts which determines whether we insist on
only adding a round of exact cuts

There may be no need to specialize the CutQueue template class. Once an 
ExternalCut rep class is created, we will simply move HyperGraphs to the
cut bank of that class. Thus the deletion of set references should not 
take place until then. 

Putting the decrementer in the call to HyperGraph deletor seems to cause
problems. There should be an external_rep class with a delete_cut member
function that calls erase on the vector of cuts and calls delete_refs on
the cut being deleted

I think LPfixing should be a derived class of LPCore? Because maybe LPCore
should be called LPManip, hence LPFixing is a type of LPManip...maybe 
LPPrune as well....

Approach: Make the main objects of LPCore protected instead of private, then
	  derived classes can access them.
	  Moreover, add a reference copy constructor to LPCore.
	  Derived classes should be constructed with any additional info they
	  need, plus a reference to LPCore from which they can construct
	  a copy of it. 

Instead of a Cut template, we should have a CutCall<typename cut_t> abstract
template class....

In preparation for column generation approach, (and also for portability?)
cut classes should not get the LP itself. They should just store a best cut
or coefficients or something and have CutControl manage the addition of cuts

With blossoms and dominos, it may make sense to store a list/pool of violated
cuts and check those before generating new ones.
Probably shouldn't bother with segments though

learn to call CPXaddrowS for multiple cuts

tooth aggregated coefficients: instead of an ecount length vector, 
create a map of type <Int, Double> mapping edges to their coeff
to be aggregated. With some checking: can call increment/decrement
even if the entries have not yet been initialized; they should
default to zero.

Light SimpleDP sep is a huge bottleneck at the moment, will probably
have to implement light tooth reduction for it to be viable,
especially since there are some examples where it allows cut
generation to proceed for longer

should store reduced costs obtained from the root node. in branch &
cut, if an augmentation takes place, we can fix edges using reduced
costs from the root and the new best tour opt value as the integrality
gap.


--

NAIVE BRANCHING
Problem with main branching is it doesn't seem to cut off the fractional 
solution? Notice how naive branching imposes a condition on the partner 
variable which guarantees that the fractional point is cut off. 

L&L say that naive branching allows too many feasible solutions on either side
of the branch (vs main where the current tour is the ONLY feasible solution
on both), but this isn't really a concern when we have an optimal starting
tour, which is often the case

BRANCHING TEMPLATIZATION
Ideal situation: have template classes
      visitor
      constraintmgr
      rightbranch
      edgestats
with function implementations specialized based on an enum class BranchPlan,
which is either main or naive. 

CUT PRUNING
the pruning mechanism of 'tight at current tour' is clearly FAR too lenient,
too many cuts accumulate and augmentation happens rarely (or never), and even
if it does we only prune 10-15 despite having hundreds possibly added

similar to the way concorde tests the age of edges/cuts, maybe record whether
cuts have been tight at a current LP solve, i.e., if we are pivoting to 
a solution where the cuts are tight. maybe test slack at current LP solution
as well, and prune cuts which have not been active for some number of
rounds

current approach is sloppy, could use a big overhaul. Ideas:
-now that no_opt/basis refactor works, could be possible to skip
re-optimizing LP

MIP CUT DENSITIES
do some experiments reporting number of nonzeros in segment and
blossom cuts, hence try to determine a reasonable number or ratio
of nonzeros and only terminate CPLEX cutting with a tight,
sufficiently sparse cut
