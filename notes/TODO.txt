COLUMN GEN!!!! Expanding a vector can invalidate references!!!!! Thus
we cannot rely on references to lp edges and edge marks, etc. All of
the constructors/use of classes should be changed to reflect
this. Maybe every fresh cutcall should grab the new edges and stuff.

In addition to LP prefs and randprob, there should be bestprefs and
graphprefs for LK trials, quad-nearest, etc. 

CUTS TO IMPLEMENT
     -Some type of block comb heuristic
     -Padberg-Hong comb/generalized comb/chain heuristics for subtours

Make more generalized use of build_s_graph for support graphs? It can
be used by just specifying support indices and an LP solution, so this
could be used to construct fractional, epsilon, etc. support graphs
Idea: pass predicate function as an argument, if true then the edge is
added to the graph

Consider implementing non-degenerate pivot through an optimization
callback that terminates optimization when objval changes. Could also
record itcount. Also, could use to get the tour row and colstat
more often. Experiment with every round, every certain number, etc.
In this way, basis copying could be fully managed by the callback
function, possibly giving better encapsulation

If augrounds is zero, need to add a switch to test if pool cuts are
still tight....

Column generation:
       suppose we get a fathomed tour on a sparse edge set. This means we have
       optimal primal/dual solutions and reduced costs. This could just mean
       we need to price/add more edges, but for the existing edges, we could
       use optimality to prune by reduced cost before scanning the edge set. 

There may be no need to specialize the CutQueue template class. Once an 
ExternalCut rep class is created, we will simply move HyperGraphs to the
cut bank of that class. Thus the deletion of set references should not 
take place until then. 

Putting the decrementer in the call to HyperGraph deletor seems to cause
problems. There should be an external_rep class with a delete_cut member
function that calls erase on the vector of cuts and calls delete_refs on
the cut being deleted

I think LPfixing should be a derived class of LPCore? Because maybe LPCore
should be called LPManip, hence LPFixing is a type of LPManip...maybe 
LPPrune as well....

Approach: Make the main objects of LPCore protected instead of private, then
	  derived classes can access them.
	  Moreover, add a reference copy constructor to LPCore.
	  Derived classes should be constructed with any additional info they
	  need, plus a reference to LPCore from which they can construct
	  a copy of it. 

In preparation for column generation approach, (and also for portability?)
cut classes should not get the LP itself. They should just store a best cut
or coefficients or something and have CutControl manage the addition of cuts

learn to call CPXaddrowS for multiple cuts

tooth aggregated coefficients: instead of an ecount length vector, 
create a map of type <Int, Double> mapping edges to their coeff
to be aggregated. With some checking: can call increment/decrement
even if the entries have not yet been initialized; they should
default to zero.

should store reduced costs obtained from the root node. in branch &
cut, if an augmentation takes place, we can fix edges using reduced
costs from the root and the new best tour opt value as the integrality
gap.


--

NAIVE BRANCHING
Problem with main branching is it doesn't seem to cut off the fractional 
solution? Notice how naive branching imposes a condition on the partner 
variable which guarantees that the fractional point is cut off. 

L&L say that naive branching allows too many feasible solutions on either side
of the branch (vs main where the current tour is the ONLY feasible solution
on both), but this isn't really a concern when we have an optimal starting
tour, which is often the case

BRANCHING TEMPLATIZATION
Ideal situation: have template classes
      visitor
      constraintmgr
      rightbranch
      edgestats
with function implementations specialized based on an enum class BranchPlan,
which is either main or naive. 

CUT PRUNING
the pruning mechanism of 'tight at current tour' is clearly FAR too lenient,
too many cuts accumulate and augmentation happens rarely (or never), and even
if it does we only prune 10-15 despite having hundreds possibly added

similar to the way concorde tests the age of edges/cuts, maybe record whether
cuts have been tight at a current LP solve, i.e., if we are pivoting to 
a solution where the cuts are tight. maybe test slack at current LP solution
as well, and prune cuts which have not been active for some number of
rounds

current approach is sloppy, could use a big overhaul. Ideas:
-now that no_opt/basis refactor works, could be possible to skip
re-optimizing LP
