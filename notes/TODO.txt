Get rid of LP and Data namespaces
Add Epsilon scoped enum with members zero = 0.00001, viol = 0.001,
gh2match = 0.3, etc. 

Put odd sep and gh sep in separate implementation files for
fastblossoms
Add loud/silent switches to separators a la concorde
Templatize cutcalls add_cuts, etc. 

Integral subtour protocol should just be to add connect cuts and pivot
until connected, don't bother with gomory thing. 

Create an encapsulated basis structure for storing row and column
status of all variables. This should have methods like
get - query CPXgetbase for resident basis and use this
make_resident - makes it so that the basis is the resident basis in
the LP problem object, hence calls to getobjval or getx will
correspond to the solution associated to this basis, etc.
init(tour) - initializes the basis for a degree LP with the current
tour

These operations could be de-coupled from LPCore....could also try
similar for support structures like support graph/indices, etc. 

Add switch for printing sequence of tour edge files in a gif-like
manner, e.g., ./PSEP -Sc8 -s1477932024 problems/pr2392.tsp

./PSEP -c8 -Su1 -s1477602901 problems/lin318.tsp adds exactly 2 cuts per
round and stagnates for hundreds and hundreds of rounds unchanged
Problem appears to be in fast blossom sep

Replace the n-1 minimum cut computations with a global mincut!!! or no??

COLUMN GEN!!!! Expanding a vector can invalidate references!!!!! Thus
we cannot rely on references to lp edges and edge marks, etc. All of
the constructors/use of classes should be changed to reflect
this. Maybe every fresh cutcall should grab the new edges and stuff.

In addition to LP prefs and randprob, there should be bestprefs and
graphprefs for LK trials, quad-nearest, etc. 

CUTS TO IMPLEMENT
     -Some type of block comb heuristic
     -Padberg-Hong comb/generalized comb/chain heuristics for subtours

Make more generalized use of build_s_graph for support graphs? It can
be used by just specifying support indices and an LP solution, so this
could be used to construct fractional, epsilon, etc. support graphs
Idea: pass predicate function as an argument, if true then the edge is
added to the graph

Consider implementing non-degenerate pivot through an optimization
callback that terminates optimization when objval changes. Could also
record itcount. Also, could use to get the tour row and colstat
more often. Experiment with every round, every certain number, etc.
In this way, basis copying could be fully managed by the callback
function, possibly giving better encapsulation

If augrounds is zero, need to add a switch to test if pool cuts are
still tight....

Column generation:
       suppose we get a fathomed tour on a sparse edge set. This means we have
       optimal primal/dual solutions and reduced costs. This could just mean
       we need to price/add more edges, but for the existing edges, we could
       use optimality to prune by reduced cost before scanning the edge set. 

There may be no need to specialize the CutQueue template class. Once an 
ExternalCut rep class is created, we will simply move HyperGraphs to the
cut bank of that class. Thus the deletion of set references should not 
take place until then. 

Putting the decrementer in the call to HyperGraph deletor seems to cause
problems. There should be an external_rep class with a delete_cut member
function that calls erase on the vector of cuts and calls delete_refs on
the cut being deleted

In preparation for column generation approach, (and also for portability?)
cut classes should not get the LP itself. They should just store a best cut
or coefficients or something and have CutControl manage the addition of cuts

learn to call CPXaddrowS for multiple cuts

tooth aggregated coefficients: instead of an ecount length vector, 
create a map of type <Int, Double> mapping edges to their coeff
to be aggregated. With some checking: can call increment/decrement
even if the entries have not yet been initialized; they should
default to zero.

should store reduced costs obtained from the root node. in branch &
cut, if an augmentation takes place, we can fix edges using reduced
costs from the root and the new best tour opt value as the integrality
gap.


--

NAIVE BRANCHING
Problem with main branching is it doesn't seem to cut off the fractional 
solution? Notice how naive branching imposes a condition on the partner 
variable which guarantees that the fractional point is cut off. 

L&L say that naive branching allows too many feasible solutions on either side
of the branch (vs main where the current tour is the ONLY feasible solution
on both), but this isn't really a concern when we have an optimal starting
tour, which is often the case

BRANCHING TEMPLATIZATION
Ideal situation: have template classes
      visitor
      constraintmgr
      rightbranch
      edgestats
with function implementations specialized based on an enum class BranchPlan,
which is either main or naive.

OBJECTIVE BRANCHING
This may be a way to emulate clamp branching in the primal case, on an
up-branch, encourage the complementary choice of variable by an
extreme perturbation of the objective function entry for that
variable. this may require updates to the LPCore to put it in a
'modified' state, wherein get_obj_val adjusts for the perturbed
objective function.

Also we may just be able to use CPXstrongbranch to help choose
branching variables. First perform one dual simplex pivot on every
fractional variable subproblem pair, then 100 on 5, then 500 on 2,
using the ranking metric in tspbook. 

CUT PRUNING
the pruning mechanism of 'tight at current tour' is clearly FAR too lenient,
too many cuts accumulate and augmentation happens rarely (or never), and even
if it does we only prune 10-15 despite having hundreds possibly added

similar to the way concorde tests the age of edges/cuts, maybe record whether
cuts have been tight at a current LP solve, i.e., if we are pivoting to 
a solution where the cuts are tight. maybe test slack at current LP solution
as well, and prune cuts which have not been active for some number of
rounds

current approach is sloppy, could use a big overhaul. Ideas:
-now that no_opt/basis refactor works, could be possible to skip
re-optimizing LP
